# local-ai-command-executer
Utilize an ultra cheap local LLM to execute any number of preloaded functions using natural language requests
